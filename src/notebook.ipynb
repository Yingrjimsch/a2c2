{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Available Windows Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install winapps\n",
    "import winapps\n",
    "cnt = 0\n",
    "for item in winapps.list_installed():\n",
    "    cnt += 1\n",
    "    print(item.name)\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GPT-4 Vision with screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert Bootstrap developer\n",
    "You take screenshots of a reference web page from the user, and then build single page apps \n",
    "using Bootstrap, HTML and JS.\n",
    "You might also be given a screenshot(The second image) of a web page that you have already built, and asked to\n",
    "update it to look more like the reference image(The first image).\n",
    "\n",
    "- Make sure the app looks exactly like the screenshot.\n",
    "- Pay close attention to background color, text color, font size, font family, \n",
    "padding, margin, border, etc. Match the colors and sizes exactly.\n",
    "- Use the exact text from the screenshot.\n",
    "- Do not add comments in the code such as \"<!-- Add other navigation links as needed -->\" and \"<!-- ... other news items ... -->\" in place of writing the full code. WRITE THE FULL CODE.\n",
    "- Repeat elements as needed to match the screenshot. For example, if there are 15 items, the code should have 15 items. DO NOT LEAVE comments like \"<!-- Repeat for each news item -->\" or bad things will happen.\n",
    "- For images, use placeholder images from https://placehold.co and include a detailed description of the image in the alt text so that an image generation AI can generate the image later.\n",
    "\n",
    "In terms of libraries,\n",
    "\n",
    "- Use this script to include Bootstrap: <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN\" crossorigin=\"anonymous\">\n",
    "- You can use Google Fonts\n",
    "- Font Awesome for icons: <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\"></link>\n",
    "\n",
    "Return only the full code in <html></html> tags.\n",
    "Do not include markdown \"```\" or \"```html\" at the start or end.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API Key\n",
    "api_key = \"\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"protimemobile.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": f\"You are an UI Expert which can easily extract single components from a webui such as buttons, input fields and other things. I will provide you with a screenshot of a mobile UI. Please describe me what website you see and provide me with a list of UI components as well as their corresponding actions.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"Conjure an emblem symbolizing the audacity of a cyberpunk pirate navigating the uncharted territories of the latent space. Imagine the pirate standing tall on the deck of a futuristic vessel, their silhouette defined by both human and cyborg traits. Picture them with cybernetic enhancements, perhaps a bionic arm or eye augmentations, hinting at their resilience and adaptability in this digital age. The scene should exude a sense of intrepid exploration, with vibrant neon hues pulsating against the backdrop of the void. Ensure the emblem's shape is unconventional, lending it a distinctive presence. Maintain a transparent background for versatility in application.\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Selenium for scraping actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install selenium\n",
    "#%pip install webdriver_manager\n",
    "import uuid\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Setup chrome driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# Navigate to the url\n",
    "driver.get('https://www.digitec.ch/')\n",
    "\n",
    "my_elements = driver.find_elements(By.TAG_NAME, 'button')\n",
    "my_elements = driver.find_elements(By.TAG_NAME, 'a')\n",
    "for element in my_elements:\n",
    "    try:\n",
    "        print(element.get_attribute(\"outerHTML\"))\n",
    "        element.screenshot(f\"components/{str(uuid.uuid4())}.png\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install selenium\n",
    "#%pip install webdriver_manager\n",
    "import uuid\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Setup chrome driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# Navigate to the url\n",
    "driver.get('https://www.digitec.ch/')\n",
    "\n",
    "my_elements = driver.find_elements(By.TAG_NAME, 'button')\n",
    "my_elements = driver.find_elements(By.TAG_NAME, 'a')\n",
    "texts = []\n",
    "for element in my_elements:\n",
    "    try:\n",
    "        if element.text:\n",
    "            texts.append(element.text)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import requests\n",
    "import io\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "n = 40\n",
    "\n",
    "\n",
    "# get all pages data\n",
    "arxiv_links = pd.read_csv('phd-survey-computer-control.csv')\n",
    "arxiv_links = arxiv_links['Url'].dropna()\n",
    "arxiv_links = arxiv_links[arxiv_links.str.contains(\"arxiv\")]\n",
    "\n",
    "papers = []\n",
    "for link in tqdm(arxiv_links):\n",
    "    link = f\"{link.replace('abs', 'pdf')}.pdf\"\n",
    "    response = requests.get(link)\n",
    "    f = io.BytesIO(response.content)\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    pages = reader.pages\n",
    "    paper_text = \"\".join([page.extract_text() for page in pages])\n",
    "    paper_text = paper_text.split(\"Reference\")[0]\n",
    "    \n",
    "    # html = urlopen(link).read()\n",
    "    # soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    # abstract = soup.find('blockquote', {'class': 'abstract'})\n",
    "    papers.append(paper_text)\n",
    "\n",
    "print(len(papers))\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorized_data = vectorizer.fit_transform(papers)\n",
    "feature_array = np.array(vectorizer.get_feature_names_out())\n",
    "top_n_indices = np.argsort(np.sum(vectorized_data.toarray(), axis=0))[-n:]\n",
    "top_n = feature_array[top_n_indices]\n",
    "print(top_n[0:n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suchen nach begriffen in papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import requests\n",
    "import io\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "n = 40\n",
    "\n",
    "\n",
    "# get all pages data\n",
    "arxiv_links = pd.read_csv('zoterophd.csv')\n",
    "arxiv_links = arxiv_links['Url'].dropna()\n",
    "arxiv_links = arxiv_links[arxiv_links.str.contains(\"arxiv\")]\n",
    "\n",
    "papers = []\n",
    "start = time.time()\n",
    "for link in tqdm(arxiv_links):\n",
    "    link = f\"{link.replace('abs', 'pdf')}.pdf\"\n",
    "    response = requests.get(link)\n",
    "    f = io.BytesIO(response.content)\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    pages = reader.pages\n",
    "    paper_text = \"\".join([page.extract_text() for page in pages])\n",
    "    paper_text = paper_text.split(\"Reference\")[0]\n",
    "    # html = urlopen(link).read()\n",
    "    # soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    # abstract = soup.find('blockquote', {'class': 'abstract'})\n",
    "    papers.append(paper_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(papers):\n",
    "    if \"dataset\" in p or \"benchmark\":\n",
    "        print(arxiv_links.iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hello this is a Reference sheet for test\".split(\"Reference\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from screenai.main import ScreenAI\n",
    "\n",
    "# Create a tensor for the image\n",
    "image = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# Create a tensor for the text\n",
    "text = torch.randn(1, 1, 512)\n",
    "\n",
    "# Create an instance of the ScreenAI model with specified parameters\n",
    "model = ScreenAI(\n",
    "    num_tokens = 20000,\n",
    "    max_seq_len = 1028,\n",
    "    patch_size=16,\n",
    "    image_size=224,\n",
    "    dim=512,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    vit_depth=4,\n",
    "    multi_modal_encoder_depth=4,\n",
    "    llm_decoder_depth=4,\n",
    "    mm_encoder_ff_mult=4,\n",
    ")\n",
    "print(model.num_tokens)\n",
    "\n",
    "# Perform forward pass of the model with the given text and image tensors\n",
    "out = model(text, image)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zeta\n",
    "print(zeta.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "pyautogui.click(50*1.4,750*1.4, interval=0.25)\n",
    "pyautogui.click(50*1.4,800*1.4, interval=0.25)\n",
    "pyautogui.typewrite(\"Microsoft Teams\", interval=0.25) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('prompts.json')\n",
    "\n",
    "test = json.load(f)\n",
    "test['debate_prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oxen.datasets import download\n",
    "from oxen.auth import config_auth\n",
    "config_auth(\"SFMyNTY.g2gDbQAAAC9hcGlfa2V5X3YxOjc1N2VhMTJjLWIyOWYtNGE5Ni04ZDhlLTE1YTIyOWRkN2NiOG4GAEA4ZoqPAWIAAVGA.U7KlA902eCE4G3DWhZNF0l3LM0Ld0cHLx2t45vhjjvE\")\n",
    "f = download(\"Yingrjimsch/a2c2_prompts\", \"prompts.json\", revision=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from PIL import Image\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeServiceimport\n",
    "import oxen\n",
    "from oxen.auth import config_auth\n",
    "import filecmp\n",
    "import uuid\n",
    "config_auth(\"SFMyNTY.g2gDbQAAAC9hcGlfa2V5X3YxOjc1N2VhMTJjLWIyOWYtNGE5Ni04ZDhlLTE1YTIyOWRkN2NiOG4GAEA4ZoqPAWIAAVGA.U7KlA902eCE4G3DWhZNF0l3LM0Ld0cHLx2t45vhjjvE\")\n",
    "\n",
    "def capture_screenshot(driver, url, output_dir, idx):\n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Allow the page to load\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Capture screenshot\n",
    "    screenshot_path = os.path.join(output_dir, f'image_{idx}.png')\n",
    "    driver.save_screenshot(screenshot_path)\n",
    "    \n",
    "    return screenshot_path\n",
    "\n",
    "def get_element_bounding_boxes(driver):\n",
    "    elements = {\n",
    "        'input': driver.find_elements(By.TAG_NAME, 'input'),\n",
    "        'a': driver.find_elements(By.TAG_NAME, 'a'),\n",
    "        'button': driver.find_elements(By.TAG_NAME, 'button')\n",
    "    }\n",
    "    \n",
    "    bounding_boxes = []\n",
    "    for element_type, elems in elements.items():\n",
    "        for elem in elems:\n",
    "            location = elem.location\n",
    "            size = elem.size\n",
    "            bounding_box = {\n",
    "                'type': element_type,\n",
    "                'x': location['x'],\n",
    "                'y': location['y'],\n",
    "                'width': size['width'],\n",
    "                'height': size['height']\n",
    "            }\n",
    "            bounding_boxes.append(bounding_box)\n",
    "    \n",
    "    return bounding_boxes\n",
    "\n",
    "def normalize_bounding_boxes(bounding_boxes, image_size):\n",
    "    image_width, image_height = image_size\n",
    "    normalized_boxes = []\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        x_center = (box['x'] + box['width'] / 2) / image_width\n",
    "        y_center = (box['y'] + box['height'] / 2) / image_height\n",
    "        width = box['width'] / image_width\n",
    "        height = box['height'] / image_height\n",
    "        if (x_center <= 0 and y_center <= 0) or x_center > 1 or y_center > 1: continue\n",
    "        normalized_boxes.append({\n",
    "            'type': box['type'],\n",
    "            'x_center': x_center,\n",
    "            'y_center': y_center,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "    return normalized_boxes\n",
    "\n",
    "def save_yolo_annotations(normalized_boxes, annotation_path):\n",
    "    with open(annotation_path, 'w') as f:\n",
    "        for box in normalized_boxes:\n",
    "            class_id = {\n",
    "                'input': 0,\n",
    "                'a': 1,\n",
    "                'button': 2\n",
    "            }[box['type']]\n",
    "            f.write(f'{class_id} {box[\"x_center\"]} {box[\"y_center\"]} {box[\"width\"]} {box[\"height\"]}\\n')\n",
    "\n",
    "def process_urls(urls, output_dir):\n",
    "    # Set up Selenium with ChromeDriver\n",
    "    # service = Service('path/to/chromedriver')\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('--headless')\n",
    "    # driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "\n",
    "    for idx, url in enumerate(urls):\n",
    "        id = str(uuid.uuid4())\n",
    "        screenshot_path = capture_screenshot(driver, url, os.path.join(output_dir, 'images'), id)\n",
    "        bounding_boxes = get_element_bounding_boxes(driver)\n",
    "        image = Image.open(screenshot_path)\n",
    "        image_size = image.size\n",
    "        normalized_boxes = normalize_bounding_boxes(bounding_boxes, image_size)\n",
    "        \n",
    "        annotation_path = os.path.join(output_dir, 'labels', f'image_{id}.txt')\n",
    "        save_yolo_annotations(normalized_boxes, annotation_path)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# # Example usage\n",
    "# urls = [\n",
    "#     'https://google.ch',\n",
    "#     'https://example.com',\n",
    "#     'https://digitec.ch'\n",
    "#     # Add more URLs as needed\n",
    "# ]\n",
    "\n",
    "def oxen_pull():\n",
    "    return oxen.clone(\"Yingrjimsch/a2c2_prompts\")\n",
    "\n",
    "def oxen_push(repo):\n",
    "    repo.add(\".\")\n",
    "    # Commit the changes with a message\n",
    "    repo.commit(\"Adding new data for training\")\n",
    "\n",
    "    # Set where to push the data to (replace <namespace> and <repo_name> with your remote)\n",
    "    repo.set_remote(\"origin\", \"https://hub.oxen.ai/Yingrjimsch/a2c2_prompts\")\n",
    "\n",
    "    # Push the changes to the remote\n",
    "    repo.push()\n",
    "\n",
    "def read_urls_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        urls = file.read().splitlines()\n",
    "    return set(urls)\n",
    "\n",
    "def get_unique_urls(file1, file2):\n",
    "    urls1 = read_urls_from_file(file1)\n",
    "    urls2 = read_urls_from_file(file2)\n",
    "    \n",
    "    unique_urls = urls1.symmetric_difference(urls2)\n",
    "    \n",
    "    return list(unique_urls)\n",
    "\n",
    "def append_list_to_file(file_path, items):\n",
    "    with open(file_path, 'a') as file:\n",
    "        for item in items:\n",
    "            file.write(f'\\n{item}')\n",
    "\n",
    "dir = oxen_pull()\n",
    "urls = get_unique_urls('url_list.txt', 'a2c2_prompts/url_list.txt')\n",
    "if not urls == []:\n",
    "    process_urls(urls, dir.path)\n",
    "    append_list_to_file(os.path.join(dir.path, 'url_list.txt'), urls)\n",
    "    oxen_push(dir)\n",
    "    \n",
    "# oxen_push(dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from oxen.auth import config_auth\n",
    "import filecmp\n",
    "import uuid\n",
    "config_auth(\"OXENAI_API_KEY\")\n",
    "oxen_push(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oxen\n",
    "from oxen.auth import config_auth\n",
    "config_auth(\"SFMyNTY.g2gDbQAAAC9hcGlfa2V5X3YxOjc1N2VhMTJjLWIyOWYtNGE5Ni04ZDhlLTE1YTIyOWRkN2NiOG4GAEA4ZoqPAWIAAVGA.U7KlA902eCE4G3DWhZNF0l3LM0Ld0cHLx2t45vhjjvE\")\n",
    "# Clone the repository\n",
    "repo = oxen.clone(\"Yingrjimsch/a2c2_prompts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from oxen import LocalRepo\n",
    "\n",
    "# Instantiate a LocalRepo object and create the repo directory\n",
    "# repo = LocalRepo(repo, mkdir=True)\n",
    "# Initialize the repository\n",
    "# repo.init()\n",
    "# Write data to a file\n",
    "data_path = os.path.join(repo.path, \"people.csv\")\n",
    "with open(data_path, \"w\") as f:\n",
    "    f.write(\"name,age\\nbob,12\\njane,13\")\n",
    "# Stage the data for commit\n",
    "repo.add(data_path)\n",
    "# Commit the changes with a message\n",
    "repo.commit(\"Adding my data\")\n",
    "\n",
    "# Set where to push the data to (replace <namespace> and <repo_name> with your remote)\n",
    "repo.set_remote(\"origin\", \"https://hub.oxen.ai/Yingrjimsch/<repo_name>\")\n",
    "\n",
    "# Push the changes to the remote\n",
    "repo.push()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filecmp\n",
    "filecmp.cmp('url_list.txt', 'a2c2_prompts/url_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def resize(width, height):\n",
    "    if width > 1024 or height > 1024:\n",
    "        if width > height:\n",
    "            height = int(height * 1024 / width)\n",
    "            width = 1024\n",
    "        else:\n",
    "            width = int(width * 1024 / height)\n",
    "            height = 1024\n",
    "    return width, height\n",
    "\n",
    "def count_image_tokens(width: int, height: int):\n",
    "    width, height = resize(width, height)\n",
    "    h = ceil(height / 512)\n",
    "    w = ceil(width / 512)\n",
    "    total = 85 + 170 * h * w\n",
    "    return total\n",
    "\n",
    "count_image_tokens(1080, 2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def count_tags(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    tags = soup.find_all(True)\n",
    "    return len(tags)\n",
    "\n",
    "# Get the path to the user's home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Construct the path to the Downloads folder\n",
    "downloads_dir = os.path.join(home_dir, 'Downloads')\n",
    "\n",
    "# Construct the absolute path to the file 'pt.html'\n",
    "file_path = os.path.join(downloads_dir, 'pt.html')\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "        num_tags = count_tags(html_content)\n",
    "        print(f'Total number of HTML tags: {num_tags}')\n",
    "else:\n",
    "    print(f'The file {file_path} does not exist.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Define a list of interactive tags\n",
    "interactive_tags = [\n",
    "    'a', 'button', 'details', 'input', 'select', 'textarea', 'label', 'fieldset',\n",
    "    'legend', 'option', 'audio', 'video', 'iframe', 'dialog', 'menu', 'menuitem',\n",
    "    'embed', 'object', 'area', 'summary'\n",
    "]\n",
    "\n",
    "def count_and_extract_interactive_tags(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    tag_count = {tag: 0 for tag in interactive_tags}\n",
    "    filtered_tags = []\n",
    "\n",
    "    for tag in interactive_tags:\n",
    "        tags = soup.find_all(tag)\n",
    "        tag_count[tag] = len(tags)\n",
    "        filtered_tags.extend(tags)\n",
    "\n",
    "    return tag_count, filtered_tags\n",
    "\n",
    "def save_filtered_tags_to_html(filtered_tags, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write('<html><head><title>Filtered Interactive Tags</title></head><body>\\n')\n",
    "        for tag in filtered_tags:\n",
    "            file.write(str(tag))\n",
    "            file.write('\\n')\n",
    "        file.write('</body></html>')\n",
    "\n",
    "# Get the path to the user's home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Construct the path to the Downloads folder\n",
    "downloads_dir = os.path.join(home_dir, 'Downloads')\n",
    "\n",
    "# Construct the absolute path to the file 'pt.html'\n",
    "file_path = os.path.join(downloads_dir, 'pt.html')\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "        tag_count, filtered_tags = count_and_extract_interactive_tags(html_content)\n",
    "        total_interactive_tags = sum(tag_count.values())\n",
    "        \n",
    "        print(f'Total number of interactive HTML tags: {total_interactive_tags}')\n",
    "        print('Detailed count per tag:')\n",
    "        for tag, count in tag_count.items():\n",
    "            print(f'{tag}: {count}')\n",
    "        \n",
    "        # Define output path for the filtered tags HTML file\n",
    "        output_path = os.path.join(downloads_dir, 'filtered_tags.html')\n",
    "        save_filtered_tags_to_html(filtered_tags, output_path)\n",
    "        print(f'Filtered tags have been saved to: {output_path}')\n",
    "else:\n",
    "    print(f'The file {file_path} does not exist.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "# Get the path to the user's home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Construct the path to the Downloads folder\n",
    "downloads_dir = os.path.join(home_dir, 'Downloads')\n",
    "\n",
    "# Construct the absolute path to the file 'pt.html'\n",
    "file_path = os.path.join(downloads_dir, 'pt.png')\n",
    "# Load image, grayscale, Gaussian blur, Otsu's threshold, dilate\n",
    "image = cv2.imread(file_path)\n",
    "original = image.copy()\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "# Find contours, obtain bounding box coordinates, and extract ROI\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "print(\"number of components:\", len(cnts))\n",
    "image_number = 0\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    print(\"Dimensions:\", w,h)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 3)\n",
    "    ROI = original[y:y+h, x:x+w]\n",
    "    cv2.imwrite(\"ROI_{}.png\".format(image_number), ROI)\n",
    "    image_number += 1\n",
    "\n",
    "cv2.imwrite(os.path.join(downloads_dir, 'pt_bbox.png'), image)\n",
    "cv2.imwrite(os.path.join(downloads_dir, 'pt_thresh.png'), thresh)\n",
    "cv2.imwrite(os.path.join(downloads_dir, 'pt_dilate.png'), dilate)\n",
    "cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "def process_file(input_path, output_path):\n",
    "    # Open the input file and read its content\n",
    "    with open(input_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Function to process each match (number in the text)\n",
    "    def process_match(match):\n",
    "        number = int(match.group(0))\n",
    "        processed_number = math.ceil(number / 2)\n",
    "        return str(processed_number)\n",
    "\n",
    "    # Replace numbers in the content\n",
    "    import re\n",
    "    modified_content = re.sub(r'(?<= )\\d+(?= )', lambda x: process_match(x), content)\n",
    "\n",
    "    # Write the modified content to the output file\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.write(modified_content)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define the input and output paths\n",
    "    input_path = os.path.join(os.environ['USERPROFILE'], 'Downloads', 'pt.txt')\n",
    "    output_path = os.path.join(os.environ['USERPROFILE'], 'Downloads', 'pt_edited.txt')\n",
    "\n",
    "    # Process the file\n",
    "    process_file(input_path, output_path)\n",
    "    print(f\"Processed file saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def change_colored_pixels_to_black(image_path, output_path):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path).convert(\"RGBA\")\n",
    "    pixels = img.load()  # Create the pixel map\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    width, height = img.size\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            r, g, b, a = pixels[x, y]\n",
    "            # If the pixel is not transparent\n",
    "            if a != 0:\n",
    "                # Change the pixel to black with the same alpha value\n",
    "                pixels[x, y] = (0, 0, 0, a)\n",
    "\n",
    "    # Save the modified image\n",
    "    img.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "input_image_path = \"paper_example_screenshots/vlm-copy.png\"\n",
    "output_image_path = \"paper_example_screenshots/vlm_copy_copy.png\"\n",
    "change_colored_pixels_to_black(input_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import nltk\n",
    "import requests\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "def download_pdf(pdf_url, output_path):\n",
    "    if os.path.exists(output_path):\n",
    "            os.remove(output_path)\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "def query(pdf_url, output_path):\n",
    "    download_pdf(pdf_url, output_path)\n",
    "    loader = UnstructuredFileLoader(output_path)\n",
    "    documents= loader.load()\n",
    "\n",
    "    # if you want to load file as a list of elements then only do this\n",
    "    loader = UnstructuredFileLoader('SamplePDF.pdf', mode='elements')\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key = os.environ['OPENAI_API_KEY'])\n",
    "    doc_search = Chroma.from_documents(texts,embeddings)\n",
    "    chain = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=doc_search)\n",
    "\n",
    "    query = \"Provide me with a list of all datasets and benchmarks used on in this paper.\"\n",
    "    return chain.run(query)\n",
    "\n",
    "query(\"https://arxiv.org/pdf/2302.04761\", \"paper.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
